{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Assignment: Transformers from Scratch"
      ],
      "metadata": {
        "id": "UP9nqzSlAHPH"
      },
      "id": "UP9nqzSlAHPH"
    },
    {
      "cell_type": "markdown",
      "id": "1d14a11b",
      "metadata": {
        "id": "1d14a11b"
      },
      "source": [
        "\n",
        "Welcome to your hands‚Äëon journey building a Transformer model from the ground up! In this notebook, you will:\n",
        "\n",
        "1. **Load & preprocess** a parallel English‚ÄìDutch corpus  \n",
        "2. **Implement** the core Transformer components (self‚Äëattention, positional encoding, encoder/decoder stacks)  \n",
        "3. **Train** your model on the dataset  \n",
        "4. **Evaluate** it using greedy decoding and compute BLEU scores  \n",
        "\n",
        "---\n",
        "\n",
        "## üìù Instructions\n",
        "\n",
        "- Throughout the notebook, you will find code cells with blanks marked as **`__________`**.  \n",
        "- **Your task is to fill in each blank** with the correct PyTorch / Python expression, function call, or parameter.  \n",
        "- Don‚Äôt change the overall structure of the cells‚Äîjust complete the missing pieces.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "- Understand the architecture and data flow of a Transformer  \n",
        "- Implement multi‚Äëhead self‚Äëattention, positional encodings, and masking  \n",
        "- Use PyTorch to build and train sequence‚Äëto‚Äësequence models  \n",
        "- Evaluate translation quality with BLEU  \n",
        "\n",
        "---\n",
        "\n",
        "## üìö Notebook Overview\n",
        "\n",
        "1. **Data Loading & Tokenization**  \n",
        "   - Load the OPUS Books `en-nl` dataset  \n",
        "   - Build source/target vocabularies  \n",
        "   - Tokenize and numericalize sentences  \n",
        "\n",
        "2. **Model Components**  \n",
        "   - Scaled dot‚Äëproduct attention  \n",
        "   - Multi‚Äëhead attention layer  \n",
        "   - Positional encoding  \n",
        "   - Encoder & decoder layers  \n",
        "\n",
        "3. **Training Loop**  \n",
        "   - Loss with optional label smoothing  \n",
        "   - Learning‚Äërate scheduler (warmup + decay)  \n",
        "   - Gradient clipping  \n",
        "\n",
        "4. **Decoding & Evaluation**  \n",
        "   - Greedy decoding implementation  \n",
        "   - Calculate BLEU on validation set  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚úçÔ∏è Submission\n",
        "\n",
        "- Make sure all **`__________`** placeholders are filled in.  \n",
        "- Verify that the notebook runs end‚Äëto‚Äëend without errors.  \n",
        "- **Push** your completed notebook to the class GitHub repo by the due date.\n",
        "\n",
        "Good luck, and happy coding! üéâ  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries if not already installed\n",
        "!pip install datasets sentencepiece\n",
        "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install torchtext==0.15.1\n"
      ],
      "metadata": {
        "id": "JP8QW7CxoGyp"
      },
      "id": "JP8QW7CxoGyp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "full_dataset = load_dataset(\"opus_books\", \"en-nl\", split=\"train\")  # or iwslt2017\n",
        "\n",
        "SRC_LANGUAGE = \"nl\"\n",
        "TGT_LANGUAGE = \"en\"\n",
        "\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "def build_vocab(dataset, lang):\n",
        "    counter = Counter()\n",
        "    for item in dataset:\n",
        "        counter.update(word_tokenize(item['translation'][lang]))\n",
        "    vocab = {sym: i for i, sym in enumerate(special_symbols)}\n",
        "    for word in counter:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "# Build vocab on full data (or just training set)\n",
        "src_vocab = build_vocab(full_dataset, \"nl\")\n",
        "tgt_vocab = build_vocab(full_dataset, \"en\")\n",
        "\n"
      ],
      "metadata": {
        "id": "cwWmsMfy7b8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "bd8607d119c443439e7ec047d9689531",
            "b5650f2e19c84cc2a4bff6286cc93e98",
            "5b5e055e9f6640349fc04b5e45a08247",
            "1cdb9799446d4ccd821115e81c63e845",
            "c3b7ca9fc5d544a4bd57dc52ec2b2a2e",
            "e19c87cdda1f4d9aaaf9bd1668ea0eec",
            "87096489046a4320802d66f6361e15fa",
            "a1e23030cb9044f4890c8c5b3f5b9e15",
            "267e49fed0b04d888294a4d7519bb19f",
            "855c1c39a0914933b6431d76c09c8a1a",
            "e2441f88b6d04276a99dce42f5c0148f",
            "21e5f475540d43efb77beb2bc4ee7b2d",
            "41bc87fc34c1483da41ee5f661a1ec2d",
            "4b0bd1339e4243d782f240b907cd5567",
            "4e5246d80e7c493faf3ce5ad6fef195f",
            "6368b7d6da4142e8be40f80629ba3092",
            "cd024eb6ad2c459dbdbb021a286f21f9",
            "d24701e251654ba4bfe7ce93d34190b7",
            "7c4d3d5266ae4438b234dc06deb6c92f",
            "240ebac9df104b2a8186c5a8140574e8",
            "6b9fa70a16ee45abb778f1167aa87ad1",
            "8f0ac0b913e34b25b13bf83fda7d64f2",
            "55c44412204c4531881f7fa21706f9c2",
            "e4eb3d726a914e7f9a6ed499b1cd76c5",
            "ab7e1412b3064b6f99ceb9b8ba14bb01",
            "6d581cfec8e54dd8a4ca59142a0f72a5",
            "6fbd43e81b8a460388b32d832aed2d5d",
            "8ee82eb9910f45718c2281271140b608",
            "25fccc85a63d4875bbcbbfb9a45497e7",
            "e7d5fd34a195406bace3b3be3f97006d",
            "002d5c728fb94db1be60c962a44be3cc",
            "e0fca806a93f4a93ace7e9364013461c",
            "dd732edaa8664faa9ab6e7796439282c"
          ]
        },
        "outputId": "77407524-1ae9-4abf-a902-5622bc948ee6"
      },
      "id": "cwWmsMfy7b8G",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd8607d119c443439e7ec047d9689531"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/6.44M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21e5f475540d43efb77beb2bc4ee7b2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/38652 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c44412204c4531881f7fa21706f9c2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Tokenize and index helpers\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "def encode(text, vocab):\n",
        "    return [vocab.get(tok, UNK_IDX) for tok in tokenize(text)]\n",
        "\n",
        "# Collate function to prepare batches\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for item in batch:\n",
        "        # Tokenize and numerify source sentence (Dutch)\n",
        "        src_indices = encode(item['translation'][SRC_LANGUAGE], src_vocab)\n",
        "        src_tensor = torch.tensor([BOS_IDX] + src_indices + [EOS_IDX], dtype=torch.long)\n",
        "        src_batch.append(src_tensor)\n",
        "\n",
        "        # Tokenize and numerify target sentence (English)\n",
        "        tgt_indices = encode(item['translation'][TGT_LANGUAGE], tgt_vocab)\n",
        "        tgt_tensor = torch.tensor([BOS_IDX] + tgt_indices + [EOS_IDX], dtype=torch.long)\n",
        "        tgt_batch.append(tgt_tensor)\n",
        "\n",
        "    # Pad sequences\n",
        "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch\n"
      ],
      "metadata": {
        "id": "wXgun3KGlE-v"
      },
      "id": "wXgun3KGlE-v",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Create matrix of shape (max_len, d_model) with positional encoding vectors\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # [max_len, 1]\n",
        "        # Compute the div term: 10000^{-2i/d_model} for even i\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float) * -(math.log(10000.0) / d_model))\n",
        "        # Apply sin to even indices, cos to odd indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # 0,2,4,... dims\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # 1,3,5,... dims\n",
        "        pe = pe.unsqueeze(0)  # shape (1, max_len, d_model) to allow broadcasting\n",
        "        self.register_buffer('pe', pe)  # register as buffer so it‚Äôs saved with model and on same device\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x shape: (batch_size, seq_len, d_model)\n",
        "        seq_len = x.size(1)\n",
        "        # Add positional encoding up to seq_len\n",
        "        x = x + self.pe[:, :seq_len, :]\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "DstFLPx6lHGV"
      },
      "id": "DstFLPx6lHGV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def scaled_dot_product_attention(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: torch.Tensor = None):\n",
        "    # Q, K, V shape: (batch, heads, seq_len_q, d_k), (batch, heads, seq_len_k, d_k), ...\n",
        "    d_k = Q.size(-1)\n",
        "    # 1. Compute raw attention scores by dot product\n",
        "    # scores shape: (batch, heads, seq_len_q, seq_len_k)\n",
        "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    # 2. Apply mask (if provided) by setting scores to -inf where mask is True\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(~mask, -1e9)\n",
        "\n",
        "    # Subtract the max for numerical stability.\n",
        "    scores = scores - scores.max(dim=-1, keepdim=True)[0]\n",
        "    # 3. Softmax to get attention weights\n",
        "    attn_weights = F.softmax(scores, dim=-1)  # along seq_len_k\n",
        "    # 4. Use weights to get weighted sum of values\n",
        "    output = torch.matmul(attn_weights, V)  # shape: (batch, heads, seq_len_q, d_k)\n",
        "    return output, attn_weights\n"
      ],
      "metadata": {
        "id": "9DVgwOCslOsj"
      },
      "id": "9DVgwOCslOsj",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "\n",
        "        # Learned projection matrices\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # For analysis, we can store attention weights if needed\n",
        "        self.attn_weights = None\n",
        "\n",
        "    def forward(self, Q_in: torch.Tensor, K_in: torch.Tensor, V_in: torch.Tensor, mask: torch.Tensor = None):\n",
        "        batch_size = Q_in.size(0)\n",
        "\n",
        "        # Linear projections\n",
        "        Q = self.W_q(Q_in)\n",
        "        K = self.W_k(K_in)\n",
        "        V = self.W_v(V_in)\n",
        "\n",
        "        # Reshape and split into heads\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.d_k).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.d_k).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.d_k).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Handle mask\n",
        "        if mask is not None:\n",
        "            # If mask is [batch, 1, seq_len, seq_len], expand to heads\n",
        "            if mask.dim() == 4 and mask.size(1) == 1:\n",
        "                mask = mask.expand(-1, self.n_heads, -1, -1)\n",
        "\n",
        "        attn_output, attn_weights = scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Concatenate heads and project\n",
        "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
        "        attn_output = attn_output.view(batch_size, -1, self.d_model)\n",
        "        output = self.W_o(attn_output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        self.attn_weights = attn_weights\n",
        "        return output"
      ],
      "metadata": {
        "id": "j07uUZSrlQiS"
      },
      "id": "j07uUZSrlQiS",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x shape: (batch, seq_len, d_model)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "B0RxzifqlSPg"
      },
      "id": "B0RxzifqlSPg",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
        "        # Self-attention sub-layer\n",
        "        attn_output = self.self_attn(x, x, x, mask=src_mask)\n",
        "        x = x + attn_output  # add residual\n",
        "        x = self.norm1(x)    # layer norm\n",
        "        # Feed-forward sub-layer\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = x + self.dropout(ffn_output)  # add residual\n",
        "        x = self.norm2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2SRu4QZ8lUBH"
      },
      "id": "2SRu4QZ8lUBH",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, enc_output: torch.Tensor, tgt_mask: torch.Tensor = None, mem_mask: torch.Tensor = None):\n",
        "        # 1. Decoder self-attention (mask out future tokens)\n",
        "        attn_output = self.self_attn(x, x, x, mask=tgt_mask)\n",
        "        x = x + attn_output\n",
        "        x = self.norm1(x)\n",
        "        # 2. Encoder-Decoder cross-attention (queries = x, keys/values = enc_output)\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, mask=mem_mask)\n",
        "        x = x + attn_output\n",
        "        x = self.norm2(x)\n",
        "        # 3. Position-wise feed-forward\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = x + self.dropout(ffn_output)\n",
        "        x = self.norm3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Bu0ICAZalVht"
      },
      "id": "Bu0ICAZalVht",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, d_model: int = 256, n_heads: int = 4,\n",
        "                 num_encoder_layers: int = 3, num_decoder_layers: int = 3, d_ff: int = 512, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        # Embedding layers\n",
        "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
        "        # Encoder and Decoder stacks\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(num_encoder_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(num_decoder_layers)])\n",
        "        # Final output linear layer\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def encode(self, src: torch.Tensor, src_mask: torch.Tensor = None):\n",
        "        # src: [batch, src_len] (token indices)\n",
        "        x = self.src_emb(src) * math.sqrt(self.d_model)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return x  # shape: [batch, src_len, d_model]\n",
        "\n",
        "    def decode(self, tgt: torch.Tensor, enc_output: torch.Tensor, tgt_mask: torch.Tensor = None, mem_mask: torch.Tensor = None):\n",
        "        # tgt: [batch, tgt_len], enc_output: [batch, src_len, d_model]\n",
        "        x = self.tgt_emb(tgt) * math.sqrt(self.d_model)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.decoder_layers:\n",
        "            x = layer(x, enc_output, tgt_mask, mem_mask)\n",
        "        return x  # shape: [batch, tgt_len, d_model]\n",
        "\n",
        "    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_mask: torch.Tensor = None,\n",
        "                tgt_mask: torch.Tensor = None, mem_mask: torch.Tensor = None):\n",
        "        enc_output = self.encode(src, src_mask)\n",
        "        dec_output = self.decode(tgt, enc_output, tgt_mask, mem_mask)\n",
        "        logits = self.fc_out(dec_output)  # raw logits for each token in tgt sequence\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "UmjBewgGlXXd"
      },
      "id": "UmjBewgGlXXd",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a small transformer for testing\n",
        "test_model = TransformerModel(\n",
        "    src_vocab_size=len(src_vocab),\n",
        "    tgt_vocab_size=len(tgt_vocab),\n",
        "    d_model=32, #512\n",
        "    n_heads=4,  #8\n",
        "    num_encoder_layers=2, #6\n",
        "    num_decoder_layers=2, #6\n",
        "    d_ff=64  #2048\n",
        "    #dropout=0.2\n",
        ")\n",
        "\n",
        "# Dummy input batch (Dutch source and English target)\n",
        "dummy_src = torch.tensor([[BOS_IDX, 5, 6, 7, EOS_IDX, PAD_IDX, PAD_IDX]], dtype=torch.long)  # [1, 7]\n",
        "dummy_tgt = torch.tensor([[BOS_IDX, 10, 11, EOS_IDX, PAD_IDX]], dtype=torch.long)  # [1, 5]\n",
        "\n",
        "# Create masks for dummy input\n",
        "def generate_masks(src, tgt):\n",
        "    # Source padding mask: [batch, 1, 1, src_len]\n",
        "    src_pad_mask = (src == PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # Target future mask: [1, 1, tgt_len, tgt_len]\n",
        "    tgt_len = tgt.size(1)\n",
        "    future_mask = torch.triu(torch.ones((tgt_len, tgt_len), dtype=torch.bool), diagonal=1)\n",
        "    future_mask = future_mask.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    # Target padding mask: [batch, 1, tgt_len, 1]\n",
        "    tgt_pad_mask = (tgt == PAD_IDX).unsqueeze(1).unsqueeze(3)\n",
        "\n",
        "    # Combined target mask: [batch, 1, tgt_len, tgt_len]\n",
        "    tgt_mask = future_mask | tgt_pad_mask\n",
        "\n",
        "    # Memory mask: [batch, 1, 1, src_len]\n",
        "    mem_mask = src_pad_mask\n",
        "\n",
        "    return src_pad_mask, tgt_mask, mem_mask\n",
        "\n",
        "# Generate masks\n",
        "src_mask, tgt_mask, mem_mask = generate_masks(dummy_src, dummy_tgt)\n",
        "\n",
        "# Forward pass\n",
        "out_logits = test_model(dummy_src, dummy_tgt, src_mask, tgt_mask, mem_mask)\n",
        "\n",
        "# Output shape\n",
        "print(\"Output logits shape:\", out_logits.shape)  # Expecting [1, 5, tgt_vocab_size]"
      ],
      "metadata": {
        "id": "1-Kbr8_glZGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15bf1c5-c110-4216-9b55-ba48ec67a48c"
      },
      "id": "1-Kbr8_glZGM",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output logits shape: torch.Size([1, 5, 30060])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration (use GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Instantiate the Transformer model\n",
        "d_model = 256   # embedding dimension\n",
        "n_heads = 8     # number of attention heads\n",
        "d_ff = 512      # feed-forward inner layer dimension\n",
        "num_layers = 4  # number of encoder and decoder layers\n",
        "model = TransformerModel(len(src_vocab),\n",
        "                         len(tgt_vocab),\n",
        "                         d_model=d_model, n_heads=n_heads,\n",
        "                         num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
        "                         d_ff=d_ff, dropout=0.1).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Function to create masks for a batch\n",
        "def create_masks(src: torch.Tensor, tgt: torch.Tensor):\n",
        "    \"\"\"\n",
        "    src: [batch, src_len], tgt: [batch, tgt_len] with BOS and EOS included in tgt.\n",
        "    Returns src_mask, tgt_mask, mem_mask.\n",
        "    \"\"\"\n",
        "    batch_size, src_len = src.size()\n",
        "    tgt_len = tgt.size(1)\n",
        "    # Encoder (src) padding mask: shape [batch, 1, 1, src_len]\n",
        "    src_pad_mask = (src == PAD_IDX).unsqueeze(1).unsqueeze(2)  # True where pad\n",
        "    # Decoder (tgt) padding mask for keys:\n",
        "    tgt_pad_mask = (tgt == PAD_IDX).unsqueeze(1).unsqueeze(3)  # [batch, 1, tgt_len, 1]\n",
        "    # Subsequent mask for decoder (to mask future positions)\n",
        "    # shape [tgt_len, tgt_len]: True where j>i\n",
        "    future_mask = torch.triu(torch.ones((tgt_len, tgt_len), device=device, dtype=torch.bool), diagonal=1)\n",
        "    future_mask = future_mask.unsqueeze(0).unsqueeze(0)  # [1, 1, tgt_len, tgt_len]\n",
        "    # Combine tgt masks: mask out future and padded keys\n",
        "    tgt_mask = future_mask | tgt_pad_mask  # broadcast over batch\n",
        "    # For decoder cross-attention: mask out source pads for each target query\n",
        "    mem_mask = src_pad_mask  # shape [batch, 1, 1, src_len] (will broadcast across tgt_len dimension in attention)\n",
        "    return src_pad_mask, tgt_mask, mem_mask\n",
        "\n",
        "# You need to define your data loaders first\n",
        "# Here's how to create them (assuming you have your dataset prepared):\n",
        "\n",
        "# First, split your dataset into train and validation\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Then create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Training loop\n",
        "NUM_EPOCHS = 10\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src_batch, tgt_batch in train_loader:\n",
        "        src_batch = src_batch.to(device)\n",
        "        tgt_batch = tgt_batch.to(device)\n",
        "        # Prepare target input and output\n",
        "        tgt_in = tgt_batch[:, :-1]   # input to decoder (everything except last token)\n",
        "        tgt_out = tgt_batch[:, 1:]   # target output (everything except first token <BOS>)\n",
        "        # Create masks\n",
        "        src_mask, tgt_mask, mem_mask = create_masks(src_batch, tgt_in)\n",
        "        # Forward pass\n",
        "        logits = model(src_batch, tgt_in, src_mask, tgt_mask, mem_mask)\n",
        "        # Compute loss (flatten the logits and targets for cross-entropy)\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src_batch, tgt_batch in val_loader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            tgt_batch = tgt_batch.to(device)\n",
        "            tgt_in = tgt_batch[:, :-1]\n",
        "            tgt_out = tgt_batch[:, 1:]\n",
        "            src_mask, tgt_mask, mem_mask = create_masks(src_batch, tgt_in)\n",
        "            logits = model(src_batch, tgt_in, src_mask, tgt_mask, mem_mask)\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch}: Train Loss = {avg_train_loss:.3f}, Val Loss = {avg_val_loss:.3f}\")"
      ],
      "metadata": {
        "id": "LWDkACXdlbO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8185fc1-fdcb-43ad-e157-37e5beacdcc4"
      },
      "id": "LWDkACXdlbO9",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1: Train Loss = 5.396, Val Loss = 3.937\n",
            "Epoch 2: Train Loss = 3.499, Val Loss = 2.894\n",
            "Epoch 3: Train Loss = 2.728, Val Loss = 2.361\n",
            "Epoch 4: Train Loss = 2.285, Val Loss = 2.079\n",
            "Epoch 5: Train Loss = 2.027, Val Loss = 1.918\n",
            "Epoch 6: Train Loss = 1.867, Val Loss = 1.813\n",
            "Epoch 7: Train Loss = 1.759, Val Loss = 1.752\n",
            "Epoch 8: Train Loss = 1.683, Val Loss = 1.702\n",
            "Epoch 9: Train Loss = 1.631, Val Loss = 1.664\n",
            "Epoch 10: Train Loss = 1.588, Val Loss = 1.649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "# invert vocab for decoding\n",
        "inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n",
        "\n",
        "def greedy_decode(model, src_sentence, max_len=50):\n",
        "    model.eval()\n",
        "    src = torch.tensor(src_sentence, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    src_mask = (src == PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
        "    enc_output = model.encode(src, src_mask)\n",
        "\n",
        "    tgt_indices = [BOS_IDX]\n",
        "    for _ in range(max_len):\n",
        "        tgt = torch.tensor(tgt_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        tgt_mask = torch.triu(\n",
        "            torch.ones((1, 1, tgt.size(1), tgt.size(1)), device=device, dtype=torch.bool),\n",
        "            diagonal=1\n",
        "        )\n",
        "        src_mask = (src == PAD_IDX).unsqueeze(1).unsqueeze(1)\n",
        "        mem_mask = src_mask.expand(-1, -1, tgt.size(1), -1)\n",
        "\n",
        "        out = model.decode(tgt, enc_output, tgt_mask, mem_mask)\n",
        "        logits = model.fc_out(out)\n",
        "        next_token = int(logits[0, -1, :].argmax(dim=-1).item())\n",
        "        tgt_indices.append(next_token)\n",
        "        if next_token == EOS_IDX:\n",
        "            break\n",
        "\n",
        "    return tgt_indices\n",
        "\n",
        "# Get first 100 samples from validation dataset\n",
        "references = []\n",
        "candidates = []\n",
        "\n",
        "for i in range(100):  # Evaluate first 100 samples\n",
        "    sample = val_dataset[i]  # Get sample from Subset\n",
        "    trans = sample['translation']  # Access the translation dict\n",
        "\n",
        "    src_text = trans[SRC_LANGUAGE]\n",
        "    tgt_text = trans[TGT_LANGUAGE]\n",
        "\n",
        "    # tokenize & encode source\n",
        "    src_tokens = tokenize(src_text)\n",
        "    src_indices = [BOS_IDX] + [src_vocab.get(tok, UNK_IDX) for tok in src_tokens] + [EOS_IDX]\n",
        "\n",
        "    # greedy decode\n",
        "    pred_indices = greedy_decode(model, src_indices, max_len=100)\n",
        "\n",
        "    # convert to tokens (skip BOS, stop at EOS)\n",
        "    pred_tokens = []\n",
        "    for idx in pred_indices[1:]:\n",
        "        if idx == EOS_IDX:\n",
        "            break\n",
        "        pred_tokens.append(inv_tgt_vocab.get(idx, '<unk>'))\n",
        "\n",
        "    # reference tokens\n",
        "    ref_tokens = tokenize(tgt_text)\n",
        "\n",
        "    candidates.append(pred_tokens)\n",
        "    references.append([ref_tokens])  # Note: BLEU expects list of references\n",
        "\n",
        "# compute BLEU on those 100\n",
        "bleu_score = bleu.corpus_bleu(references, candidates)\n",
        "print(f\"BLEU score on first 100 sentences: {bleu_score:.3f}\")"
      ],
      "metadata": {
        "id": "nRsfXj77lc90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65d2446-b8cb-42a6-d42a-de2c700ff5a0"
      },
      "id": "nRsfXj77lc90",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score on first 100 sentences: 0.000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd8607d119c443439e7ec047d9689531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5650f2e19c84cc2a4bff6286cc93e98",
              "IPY_MODEL_5b5e055e9f6640349fc04b5e45a08247",
              "IPY_MODEL_1cdb9799446d4ccd821115e81c63e845"
            ],
            "layout": "IPY_MODEL_c3b7ca9fc5d544a4bd57dc52ec2b2a2e"
          }
        },
        "b5650f2e19c84cc2a4bff6286cc93e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e19c87cdda1f4d9aaaf9bd1668ea0eec",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_87096489046a4320802d66f6361e15fa",
            "value": "README.md:‚Äá100%"
          }
        },
        "5b5e055e9f6640349fc04b5e45a08247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e23030cb9044f4890c8c5b3f5b9e15",
            "max": 28064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_267e49fed0b04d888294a4d7519bb19f",
            "value": 28064
          }
        },
        "1cdb9799446d4ccd821115e81c63e845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855c1c39a0914933b6431d76c09c8a1a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e2441f88b6d04276a99dce42f5c0148f",
            "value": "‚Äá28.1k/28.1k‚Äá[00:00&lt;00:00,‚Äá1.96MB/s]"
          }
        },
        "c3b7ca9fc5d544a4bd57dc52ec2b2a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e19c87cdda1f4d9aaaf9bd1668ea0eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87096489046a4320802d66f6361e15fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1e23030cb9044f4890c8c5b3f5b9e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267e49fed0b04d888294a4d7519bb19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "855c1c39a0914933b6431d76c09c8a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2441f88b6d04276a99dce42f5c0148f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e5f475540d43efb77beb2bc4ee7b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41bc87fc34c1483da41ee5f661a1ec2d",
              "IPY_MODEL_4b0bd1339e4243d782f240b907cd5567",
              "IPY_MODEL_4e5246d80e7c493faf3ce5ad6fef195f"
            ],
            "layout": "IPY_MODEL_6368b7d6da4142e8be40f80629ba3092"
          }
        },
        "41bc87fc34c1483da41ee5f661a1ec2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd024eb6ad2c459dbdbb021a286f21f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d24701e251654ba4bfe7ce93d34190b7",
            "value": "train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "4b0bd1339e4243d782f240b907cd5567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4d3d5266ae4438b234dc06deb6c92f",
            "max": 6443323,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_240ebac9df104b2a8186c5a8140574e8",
            "value": 6443323
          }
        },
        "4e5246d80e7c493faf3ce5ad6fef195f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9fa70a16ee45abb778f1167aa87ad1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f0ac0b913e34b25b13bf83fda7d64f2",
            "value": "‚Äá6.44M/6.44M‚Äá[00:00&lt;00:00,‚Äá28.5MB/s]"
          }
        },
        "6368b7d6da4142e8be40f80629ba3092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd024eb6ad2c459dbdbb021a286f21f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24701e251654ba4bfe7ce93d34190b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c4d3d5266ae4438b234dc06deb6c92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240ebac9df104b2a8186c5a8140574e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b9fa70a16ee45abb778f1167aa87ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0ac0b913e34b25b13bf83fda7d64f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c44412204c4531881f7fa21706f9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4eb3d726a914e7f9a6ed499b1cd76c5",
              "IPY_MODEL_ab7e1412b3064b6f99ceb9b8ba14bb01",
              "IPY_MODEL_6d581cfec8e54dd8a4ca59142a0f72a5"
            ],
            "layout": "IPY_MODEL_6fbd43e81b8a460388b32d832aed2d5d"
          }
        },
        "e4eb3d726a914e7f9a6ed499b1cd76c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee82eb9910f45718c2281271140b608",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_25fccc85a63d4875bbcbbfb9a45497e7",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "ab7e1412b3064b6f99ceb9b8ba14bb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d5fd34a195406bace3b3be3f97006d",
            "max": 38652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_002d5c728fb94db1be60c962a44be3cc",
            "value": 38652
          }
        },
        "6d581cfec8e54dd8a4ca59142a0f72a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0fca806a93f4a93ace7e9364013461c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dd732edaa8664faa9ab6e7796439282c",
            "value": "‚Äá38652/38652‚Äá[00:00&lt;00:00,‚Äá351782.45‚Äáexamples/s]"
          }
        },
        "6fbd43e81b8a460388b32d832aed2d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee82eb9910f45718c2281271140b608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25fccc85a63d4875bbcbbfb9a45497e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d5fd34a195406bace3b3be3f97006d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002d5c728fb94db1be60c962a44be3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0fca806a93f4a93ace7e9364013461c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd732edaa8664faa9ab6e7796439282c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}